{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSA RL Training in Google Colab\n",
        "\n",
        "This notebook sets up and runs the DSA RL training pipeline.\n",
        "\n",
        "## ‚ö†Ô∏è IMPORTANT: GPU Required\n",
        "\n",
        "**You MUST enable GPU before running this notebook:**\n",
        "1. Go to: **Runtime ‚Üí Change runtime type**\n",
        "2. Set **Hardware accelerator: GPU**\n",
        "3. Click **Save**\n",
        "4. The notebook will verify GPU is available before proceeding\n",
        "\n",
        "**Training will fail without GPU** - CPU training is too slow and will timeout.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Check CUDA Version (Optional)\n",
        "\n",
        "Run this first to verify your CUDA version before installing PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check CUDA version and GPU availability\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Checking GPU and CUDA availability...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    # Try to get GPU info (using valid nvidia-smi fields)\n",
        "    result = subprocess.run(['nvidia-smi', '--query-gpu=name,driver_version,memory.total', \n",
        "                            '--format=csv,noheader'], \n",
        "                           capture_output=True, text=True, timeout=5)\n",
        "    \n",
        "    if result.returncode == 0 and result.stdout.strip():\n",
        "        print(\"‚úÖ GPU Information:\")\n",
        "        lines = result.stdout.strip().split('\\n')\n",
        "        for i, line in enumerate(lines, 1):\n",
        "            parts = [p.strip() for p in line.split(',')]\n",
        "            if len(parts) >= 3:\n",
        "                print(f\"   GPU {i}: {parts[0]}\")\n",
        "                print(f\"   Driver Version: {parts[1]}\")\n",
        "                print(f\"   Memory: {parts[2]}\")\n",
        "                print()\n",
        "        \n",
        "        # Get CUDA version from nvidia-smi header (it's shown there)\n",
        "        cuda_result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
        "        if cuda_result.returncode == 0:\n",
        "            for line in cuda_result.stdout.split('\\n'):\n",
        "                if 'CUDA Version' in line:\n",
        "                    print(f\"   {line.strip()}\")\n",
        "                    break\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  nvidia-smi returned no output\")\n",
        "        print(\"   This might mean GPU runtime is not enabled\")\n",
        "        print(\"   Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "        \n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå nvidia-smi not found\")\n",
        "    print(\"   GPU runtime may not be enabled\")\n",
        "    print(\"   Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚ö†Ô∏è  nvidia-smi timed out\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not check GPU: {e}\")\n",
        "    print(\"   Will verify after PyTorch installation\")\n",
        "\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "**Note:** We use `pip` (not conda) because:\n",
        "- Colab doesn't have conda pre-installed\n",
        "- pip is simpler and works perfectly with Colab's GPU setup\n",
        "- PyTorch wheels from pip work seamlessly with Colab's CUDA 12.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA support (Colab uses CUDA 12.4)\n",
        "# Using cu121 which is compatible with CUDA 12.4\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install numpy>=1.21.0 scipy>=1.7.0 opencv-python>=4.5.0 matplotlib>=3.4.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Repository\n",
        "4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone your repository\n",
        "# Replace YOUR_USERNAME with your GitHub username\n",
        "!git clone https://github.com/MahsaAbadian/DSA-RL-Tracker.git\n",
        "\n",
        "# Or if you've already cloned it, skip the clone step above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Navigate to Experiment1 Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Navigate to Experiment1 directory\n",
        "os.chdir('/content/DSA-RL-Tracker/Experiment1')\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path (both Experiment1 and src directories)\n",
        "sys.path.insert(0, '/content/DSA-RL-Tracker/Experiment1')\n",
        "sys.path.insert(0, '/content/DSA-RL-Tracker/Experiment1/src')\n",
        "\n",
        "# List files to verify\n",
        "print(\"\\nFiles in Experiment1:\")\n",
        "!ls -la\n",
        "print(\"\\nFiles in src:\")\n",
        "!ls -la src/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Verify GPU Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"\\n‚úÖ GPU is ready for training!\")\n",
        "else:\n",
        "    print(\"\\n‚ùå ERROR: GPU is not available!\")\n",
        "    print(\"\\n‚ö†Ô∏è  Training requires GPU acceleration.\")\n",
        "    print(\"   Please enable GPU:\")\n",
        "    print(\"   1. Go to: Runtime ‚Üí Change runtime type\")\n",
        "    print(\"   2. Set Hardware accelerator: GPU\")\n",
        "    print(\"   3. Click Save\")\n",
        "    print(\"   4. Re-run this cell\")\n",
        "    print(\"\\n   Training will be extremely slow on CPU and may timeout.\")\n",
        "    raise RuntimeError(\"GPU not available. Please enable GPU runtime before continuing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify Required Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if all required files exist\n",
        "required_files = [\n",
        "    'src/train.py',\n",
        "    'src/models.py',\n",
        "    'src/curve_generator.py',\n",
        "    'curve_config.json'\n",
        "]\n",
        "\n",
        "print(\"Checking required files...\")\n",
        "all_exist = True\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"‚úÖ {file}\")\n",
        "    else:\n",
        "        print(f\"‚ùå {file} - MISSING!\")\n",
        "        all_exist = False\n",
        "\n",
        "if all_exist:\n",
        "    print(\"\\n‚úÖ All required files found!\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Some files are missing. Please check your repository.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Training\n",
        "\n",
        "**Note:** Training will take several hours. The script saves checkpoints every 2000 episodes, so you can resume if interrupted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import training function\n",
        "from src.train import run_unified_training\n",
        "\n",
        "# Start training\n",
        "# This will:\n",
        "# - Create a timestamped run directory in runs/\n",
        "# - Train through 3 curriculum stages\n",
        "# - Save checkpoints every 2000 episodes\n",
        "# - Save final weights after each stage\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "run_unified_training(\n",
        "    run_dir=None,  # Auto-create timestamped directory\n",
        "    base_seed=42,  # For reproducibility\n",
        "    clean_previous=False,  # Keep previous runs\n",
        "    experiment_name=\"colab_training\",  # Name for this experiment\n",
        "    resume_from=None,  # Start fresh (or provide checkpoint path to resume)\n",
        "    curve_config_path=\"curve_config.json\"  # Config file\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"‚úÖ Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Monitor Training Progress (Optional)\n",
        "\n",
        "Run this cell periodically to check training progress without interrupting training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Find the latest run directory\n",
        "run_dirs = glob.glob('runs/*/')\n",
        "if run_dirs:\n",
        "    latest_run = max(run_dirs, key=os.path.getctime)\n",
        "    log_file = os.path.join(latest_run, 'logs', 'training.log')\n",
        "    \n",
        "    print(f\"üìä Latest run: {latest_run}\")\n",
        "    \n",
        "    if os.path.exists(log_file):\n",
        "        print(\"\\n=== Last 30 lines of training log ===\")\n",
        "        with open(log_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines[-30:]:\n",
        "                print(line.rstrip())\n",
        "    else:\n",
        "        print(f\"Log file not found: {log_file}\")\n",
        "        \n",
        "    # Show checkpoints\n",
        "    checkpoint_dir = os.path.join(latest_run, 'checkpoints')\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
        "        if checkpoints:\n",
        "            print(f\"\\nüì¶ Checkpoints ({len(checkpoints)} total):\")\n",
        "            for ckpt in sorted(checkpoints)[-5:]:  # Show last 5\n",
        "                size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
        "                print(f\"   {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"No runs found yet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Download Results (Optional)\n",
        "\n",
        "Download checkpoints and training results to your local machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Find latest run\n",
        "run_dirs = glob.glob('runs/*/')\n",
        "if run_dirs:\n",
        "    latest_run = max(run_dirs, key=os.path.getctime)\n",
        "    \n",
        "    # Create zip file\n",
        "    zip_path = f'{latest_run.rstrip(\"/\")}.zip'\n",
        "    print(f\"üì¶ Creating zip file: {zip_path}\")\n",
        "    \n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, filenames in os.walk(latest_run):\n",
        "            for filename in filenames:\n",
        "                file_path = os.path.join(root, filename)\n",
        "                arcname = os.path.relpath(file_path, os.path.dirname(latest_run))\n",
        "                zipf.write(file_path, arcname)\n",
        "    \n",
        "    # Download\n",
        "    print(f\"‚¨áÔ∏è  Downloading: {zip_path}\")\n",
        "    files.download(zip_path)\n",
        "    print(f\"‚úÖ Download complete!\")\n",
        "else:\n",
        "    print(\"No runs found to download\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resume Training (If Interrupted)\n",
        "\n",
        "If your Colab session times out or training is interrupted, you can resume from the last checkpoint:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Resume from a checkpoint\n",
        "# Replace the path below with your actual checkpoint path\n",
        "\n",
        "# Find latest checkpoint\n",
        "run_dirs = glob.glob('runs/*/')\n",
        "if run_dirs:\n",
        "    latest_run = max(run_dirs, key=os.path.getctime)\n",
        "    checkpoint_dir = os.path.join(latest_run, 'checkpoints')\n",
        "    \n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        checkpoints = sorted(glob.glob(os.path.join(checkpoint_dir, 'ckpt_*.pth')))\n",
        "        if checkpoints:\n",
        "            latest_checkpoint = checkpoints[-1]\n",
        "            print(f\"Found checkpoint: {latest_checkpoint}\")\n",
        "            \n",
        "            # Resume training\n",
        "            from src.train import run_unified_training\n",
        "            \n",
        "            run_unified_training(\n",
        "                resume_from=latest_checkpoint,\n",
        "                curve_config_path=\"curve_config.json\"\n",
        "            )\n",
        "        else:\n",
        "            print(\"No checkpoints found\")\n",
        "    else:\n",
        "        print(\"Checkpoint directory not found\")\n",
        "else:\n",
        "    print(\"No runs found\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
